{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q-A-summary_seq-to-seq-simple.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "d3mUnjluSRwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/Q-A summary/\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpmB1CK7SRQT",
        "outputId": "b8e49016-3809-41e7-e5f3-1cffbc74a287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AutoMaster_TrainSet.csv',\n",
              " 'AutoMaster_TestSet.csv',\n",
              " 'stop',\n",
              " 'merged_train_test_seg_data.csv',\n",
              " 'word2vec.model',\n",
              " 'wordcloud.png',\n",
              " 'new_word2vec_model',\n",
              " 'train_x_pad',\n",
              " 'train_y_pad',\n",
              " 'test_x_pad',\n",
              " 'save_embedding_matrix_path',\n",
              " 'embedding_matrix.txt',\n",
              " 'embedding_matrix.txt.npy',\n",
              " 'train_x_pad.txt',\n",
              " 'train_y_pad.txt',\n",
              " 'test_x_pad.txt',\n",
              " 'train_x_pad.txt.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Q30I18U8SmVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix_path='embedding_matrix.txt'"
      ],
      "metadata": {
        "id": "7aisTT_vTUxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines=[]\n",
        "with open(embedding_matrix_path) as f:\n",
        "    for line in f:\n",
        "        l=line.split(\" \")\n",
        "        l=[float(i) for i in l]\n",
        "        lines.append(l)\n",
        "np.save(embedding_matrix_path,lines)"
      ],
      "metadata": {
        "id": "N5-3V-YbUqTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix=np.array(lines)"
      ],
      "metadata": {
        "id": "yMyUMmo1UqZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd89gIqMknHR",
        "outputId": "f7a37b99-9668-48f0-ddf4-70505e3781de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31937, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path):\n",
        "  lines=[]\n",
        "  with open(path) as f:\n",
        "    for line in f:\n",
        "        l=line.split(\" \")\n",
        "        l=[int(float(i)) for i in l]\n",
        "        lines.append(l)\n",
        "  return np.array(lines)\n",
        "\n",
        "train_x=read_data(\"train_x_pad.txt\")\n",
        "train_y=read_data(\"train_y_pad.txt\")\n",
        "test_x=read_data(\"test_x_pad.txt\")\n"
      ],
      "metadata": {
        "id": "58VGA5Xrq32U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Seq-to-Seq Model "
      ],
      "metadata": {
        "id": "_0cYUFSJTOPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "def seq2seq(input_length, output_sequence_length, embedding_matrix, vocab_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=200, weights=[embedding_matrix], trainable=False,\n",
        "                        input_length=input_length))\n",
        "    model.add(Bidirectional(GRU(200, return_sequences=False)))\n",
        "    model.add(Dense(200, activation=\"relu\"))\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    model.add(Bidirectional(GRU(200, return_sequences=True)))\n",
        "    model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(1e-3))\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "D_oxAOuvS81L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 输入的长度   x  max_len\n",
        "input_length = train_x.shape[1]\n",
        "# 输出的长度  y  max_len\n",
        "output_sequence_length = train_y.shape[1]\n",
        "# 词表大小\n",
        "vocab_size=31937"
      ],
      "metadata": {
        "id": "9LHPqQsgmk80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = seq2seq(input_length,output_sequence_length,embedding_matrix,vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHx6S-jvmlo-",
        "outputId": "e2e9ab03-75fa-47d9-e217-6a19d1395ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 415, 200)          6387400   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 400)              482400    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               80200     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 35, 200)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 35, 400)          482400    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 35, 31937)        12806737  \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,239,137\n",
            "Trainable params: 13,851,737\n",
            "Non-trainable params: 6,387,400\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_x, train_y, batch_size=32, epochs=5, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it743cQrnOO5",
        "outputId": "67d54e9a-bbea-4c0c-c2fc-1728e5ddcbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2040/2040 [==============================] - 229s 112ms/step - loss: 2.7415 - val_loss: 2.6819\n",
            "Epoch 2/10\n",
            "2040/2040 [==============================] - 235s 115ms/step - loss: 2.5878 - val_loss: 2.5943\n",
            "Epoch 3/10\n",
            "2040/2040 [==============================] - 236s 116ms/step - loss: 2.4811 - val_loss: 2.5581\n",
            "Epoch 4/10\n",
            "2040/2040 [==============================] - 235s 115ms/step - loss: 2.4004 - val_loss: 2.5371\n",
            "Epoch 5/10\n",
            "2040/2040 [==============================] - 236s 116ms/step - loss: 2.3339 - val_loss: 2.5450\n",
            "Epoch 6/10\n",
            "2040/2040 [==============================] - 236s 116ms/step - loss: 2.2723 - val_loss: 2.5460\n",
            "Epoch 7/10\n",
            "2040/2040 [==============================] - 236s 116ms/step - loss: 2.2167 - val_loss: 2.5644\n",
            "Epoch 8/10\n",
            "2040/2040 [==============================] - 236s 116ms/step - loss: 2.1666 - val_loss: 2.5914\n",
            "Epoch 9/10\n",
            "2040/2040 [==============================] - 237s 116ms/step - loss: 2.1237 - val_loss: 2.6138\n",
            "Epoch 10/10\n",
            "2040/2040 [==============================] - 236s 116ms/step - loss: 2.0851 - val_loss: 2.6401\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd7900d1610>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Encoder(即第一个GRU) 只在序列结束时输出一个语义向量，所以其 \"return_sequences\" 参数设置为 \"False\"  \n",
        "* Decoder(即第二个GRU) 需要在每一个 time step 都输出，所以其 \"return_sequences\" 参数设置为 \"True\"  \n",
        "* 使用 \"RepeatVector\" 将 Encoder 的输出(最后一个 time step)复制 N 份作为 Decoder 的N次输入  \n",
        "* TimeDistributed 是为了保证 Dense 和 Decoder 之间的一致，可以不用太关心  \n",
        "* 但其实并不符合Seq-seq论文的模型要求：不符合Decoder的每一个时刻的输出作为下一个时刻的输入  "
      ],
      "metadata": {
        "id": "rptOWE5Glcan"
      }
    }
  ]
}